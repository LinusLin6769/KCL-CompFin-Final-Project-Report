\chapter{Background}\label{ch: background}

This chapter presents a comprehensive theoretical background to the topics related to our experiment and analyses.

\section{Univariate Time Series Forecasting}
In this section, we discuss the topic of univariate time series forecasting.

\subsection{General Notions of Time Series Forecasting}
A time series is a sequential collection of random variables indexed by time. Suppose the random variables are of one dimension. The time series is considered univariate\footnote{If the random variables are of dimension higher than one, then the time series is considered multivariate. Datasets in such form are also referred to as panel data.}. In this section, the discussions fall within the context of univariate time series forecasting. Let $Y = \{Y_{t_i} \}_{i = 1, 2, \cdots, n}$ be an univariate time series with $ Y_{t_i} \in \mathbb{R}, \; \forall i, \; n \in \mathbb{N}$ and $t = \{t_i \}_{i = 1, 2, \cdots, n}$ being the set of time indices of $Y$ (also referred to as the set of timestamps). Let $\mathcal{Y}_{t_k}$ be the largest information set about $Y$ that is accessible to the model at time point $t_k \in t$, e.g., we might have the observations of $Y$ being known ($\{Y_{t_j} = y_{t_j}\}_{j = 1, 2, \cdots, k } \subset \mathcal{Y}_{t_k}$). Then in the context of modelling, for an unknown (random) target $Y_{t_s}$ with $s > k, \; s \in \mathbb{N}$, we can articulate the notion of forecasting as the following:
\begin{displayquote}
    Forecasting the value $Y_{t_s}$ at time point $t_k$ is to find a function $f(\mathcal{Y}_{t_k}) = \widehat{Y_{t_s}}$, such that $\widehat{Y_{t_s}}$ is a good estimation of $Y_{t_s}$.
\end{displayquote}
We can develop all sorts of functions $f$ for such forecasting objectives. Functions devised to serve the objective are referred to as models. In a general sense, the notion of modelling refers to the methodologies of devising a model that serves the objective well. In particular, for any arbitrary pair of $t_k$ and $t_s$, we want to have a model $f(\mathcal{Y}_{t_k})$ such that it gives us a reliable estimation of $Y_{t_s}$.

\subsubsection{Gap}
Notice that a modelling objective is parameterised by the pair of time indices $(t_k, t_s)$. The timestamp $t_k$ directly affects the information set $\mathcal{Y}_{t_k}$ and thus determines the information the model $f$ can utilise. The timestamp $t_s$, on the other hand, controls how far in the future we are forecasting. If the gap between the two timestamps is big, the model is asked to forecast further into the future. If the gap between the two timestamps is small, then the objective might be considered easier because we are only trying to look a tiny step ahead into the future. In order to better communicate and characterise the forecasting objective, we formalise this gap between the pair of timestamps as the \textit{gap} and denote it as $\tau$:
\begin{equation*}
    \tau = t_s - t_k
\end{equation*}
With such a notion of the gap, we can then articulate the forecasting objective as $\tau$ ahead forecasting. $\tau$ takes the format of the timestamps. Depending on the format of the timestamps, the objective can be one-step ahead forecasting or one-year ahead forecasting. We will go into topics concerning timestamps in one of the upcoming paragraphs.

\subsubsection{Forecast Horizon}
Observe that the target we have in the previous forecasting objective $Y_{t_s}$ is a single value in the future. It is possible to generalise the target and have multiple targets in the future. The number of targets we try to forecast is called the \textit{forecast horizon}. Having a forecast horizon equal to one is to forecast one value into the future, and having a forecast horizon equal to five is to forecast all five values into the future. To put it formally, let $\langle \cdot \rangle$ be a counting operation that counts the number of elements for a finite set, and let a task have a finite collection of unknown values $Y_S = \{ Y_{s_1}, Y_{s_2}, \cdots \}_{s_1, s_2, \cdots \in t, \; s_1, s_2, \cdots > t_k}$. Then the forecast horizon of such a task is denoted as
\begin{equation*}
    H = \langle Y_S \rangle
\end{equation*}

\subsubsection{Timestamps}
In a time series, the time index of a random variable carries information about the time point in which the random variable lives in the time domain. In some sense, the timestamps mark the `location' of the random variables on a timeline. For example, a monthly revenue time series $Y$ in an arbitrary year can have the set of months in a year as its timestamp set and be denoted as $Y = \{ Y_{Jan}, Y_{Feb}, Y_{Mar}, \cdots, Y_{Dec} \}$. The time indices also tell us the time-relevance (geological relationship on a timeline) of the random variables among each other. In fact, the time-relevance of the random variables in a time series plays a crucial role in time series analysis. We often have to perform mathematical operations involving such relationships. An example is our coming up with the gap measurement we addressed in the previous paragraph. Another example is the calculation of the relative growth of the time series. The need for these math operations pushes modellers to devise innovative ways to define the timestamps because we cannot easily perform calculations on notations like $September$ or $Friday$. To put it in math terms, what we often do is to have a mapping from physical timestamps to the real number line (or a subset of the real number set, say, the natural number set) and use the target set of this mapping as the timestamp set for math operations. In the next paragraph, we discuss some examples of such mapping.

Take the previous monthly revenue time series as an example; one simplest way is to index the time series chronologically with natural numbers $\{ 1, 2, 3, \cdots, 12 \}$. The new index system allows for mathematical operations on the timestamps, such as addition. The objective of two-month ahead forecasting can be considered as two-step ahead forecasting with $\tau = 2$. Three-month moving average of the time series can now be of a generalised form of a three-step moving average. Another good example is the financial studies of stochastic processes, in which we often use the non-negative real line and adopt an annual scale, i.e., the starting point of the time series is indexed as $0$, one month after that is indexed $0.0833$, one-year time point is indexed $1.0$, and so on. This is particularly useful when we expand the time series studies using Stochastic Differential Equations (SDE). Let the SDE of a stochastic process $dY_t$ be given as
\begin{equation*}
    \frac{dY_t}{Y_t} = \mu_t dt + \sigma_t dW_t, \quad dW_t \sim N(0, dt).
\end{equation*}
$dt$ in the drift term is now properly defined as a real number on which we can do all sorts of math operations (observe how $dW_t$ is defined as a Brownian Motion that follows a Gaussian distribution with variance $dt$).

\subsubsection{Time Heterogeneity}
There are cases where the timestamps of the time series are not identically spaced between consecutive random variables. The previous example of monthly revenue in a year is one of them due to the months having different durations. Time series as such is technically referred to as being \textit{time heterogeneous}\footnote{Time heterogeneity is common in financial time series due to the nature of how financial markets work. For example, most markets are open only during working hours on working days. Another example is the high-frequency financial time series (see Dacarogna et al. \citeyear{genccay2001introduction})}\footnote{\textit{Time homogeneity} is the counterpart of time heterogeneity, specifying time series which have equally spaced timestamps}. Time heterogeneity can be an interesting source of information carried by the time series but can also be a major issue in time series studies. The following paragraph presents a common problem caused by time heterogeneity.

Calculating measurements related to the unit of time can be a problem with time heterogeneous time series. One common example of such measurement is the return used in finance. Return measures the relative change of the price (or, say, value) over a period of time with respect to its initial level. Several definitions can be drawn to the notion of return, but we will look at the simplest one as they all exhibit the same relationship with time heterogeneity. Let $Y = \{ Y_{t_i} \}_{i = 1, 2, \cdots n}, \; n \in \mathbb{N}$ now be a time series of the price movement of an asset over time, and the time index set being $t = \{ t_i \}_{i = 1, 2, \cdots, n}$. Define the corresponding net return measure as
\begin{equation*}
R_{t_i} = \frac{Y_{t_i} - Y_{t_{i-1}}}{Y_{t_{i-1}}}, \quad i \in \{2, 3, \cdots, n \}.
\end{equation*}
The net return $R_{t_i}$ for some $i$ is thus the relative price change of $Y_{t_i}$ over the time period $t_i - t_{i-1}$ with respect to $Y_{t_{i-1}}$. Let $R = \{ R_{t_i} \}_{i = 2, 3, \cdots, n}$ be the time series of one-step net returns derived from $Y$. If $t$ is equally spaced by, say, a day, the time series $Y$ is time-homogeneous. The time series $R$ we calculated is a time series of daily net return of $Y$. Nevertheless, in the case where $t$ is not equally spaced, the time series $Y$ is time heterogeneous. Then we no longer know the period of the net returns $R$ we calculated from the time series $Y$. This is an example of how time heterogeneity can complicate time series analyses. Time heterogeneity in finance has been studied a lot, especially with the popularisation of electronic systems. See Dacarogna et al. (\citeyear{genccay2001introduction}) for more information.

\subsection{Machine Learning Regression Modelling}
In this section, we further discuss univariate time series modelling and address how we approach the articulated forecasting objective with Machine Learning (ML) regression modelling. In addition to addressing the approach, we also provide relevant statistical notions that can be seen as the underlying theoretical foundation of the standard machine learning procedure.

Recall the forecasting objective is to come up with a model $f$ capable of generating `good' estimations of some target $Y_{t_s}$ at time $t_k$ using the provided information $\mathcal{Y}_{t_k}$. We will see in the later paragraphs that this is very similar to the process of solving for a Quasi-Maximum Likelihood Estimation (QMLE) in a statistical sense (White (\citeyear{white1982maximum})). In the context of modelling, the procedure is normally to gather the available information and formulate it into an optimisation problem: we define a fitness measure (like the `L' in QMLE), which should be a function of the estimates $f(\mathcal{Y}_{t_k})$ and the target, and we then optimise the fitness as an objective function with respect to the model $f$ in some algorithmic way (the `M' in QMLE). The final output of such a procedure will be a model (function $f$) that optimally serves our objective (the `E' in QMLE). In the remainder of this section, we discuss the general framework of how the procedure works.

\subsubsection{The Design Matrix and Target}
In regression problems, the design matrix and the target are made from accessible information and formulated for a modelling environment. In this paragraph, we discuss how to develop the design matrix and target in univariate time series modelling. Recall that the forecasting objective is to estimate $Y_{t_s}$ at time point $t_k$, with the gap $\tau = t_s - t_k > 0$ and the model is only able to utilise the accessible information set $\mathcal{Y}_{t_k}$. This dataset is called the \textit{training set}. For our modelling problem, we can only use what is provided in our training set $\mathcal{Y}_{t_k}$. The idea is to create a sandbox in which we simulate the modelling process. The design matrix and the target create this sandbox (environment). Without loss of generality, for the target $Y_{t_s}$, the information set accessible is $\mathcal{Y}_{t_s - \tau}$. In the event we have a one dimensional time series, $\mathcal{Y}_{t_s-\tau}$ is simply the collection of realised values of $Y$ until time point $t_s-\tau = t_k$, namely
\begin{equation*}
    \mathcal{Y}_{t_s-\tau} = \{ Y_{t_s-\tau} = y_{t_s-\tau}, Y_{t_{s-1}-\tau} = y_{t_{s-1}-\tau}, Y_{t_{s-2}-\tau} = y_{t_{s-2}-\tau}, \cdots, Y_{t_1} = y_{t_1} \}.
\end{equation*}
With this long list of past observations, there is a parameter we have to decide, which controls the number of past observations the model will use for a single prediction. Such parameter is called the \textit{number of lags}\footnote{Its naming originates in autoregressive estimation in time series studies. Such estimation aims at finding the optimal order of the autoregressive feature of a time series. Typically, such order is referred to as the \textit{lag}.}. Let the number of lag be denoted as $\lambda, \; \lambda \in \mathbb{N}, \; \lambda \ll k$. Then the values we allow the model to use for some target $Y_{t_i}$ is
\begin{equation*}
    \mathcal{Y}_{t_i-\tau} = \{ y_{t_i-\tau}, y_{t_{i-1}-\tau}, y_{t_{i-2}-\tau}, \cdots, y_{t_{i-\lambda}-\tau} \}.
\end{equation*}
Then the design matrix $\matr{X}$ and the corresponding $\matr{y}$ can be formulated as
\begin{equation*}
    \matr{y} = \begin{bmatrix}
        y_{t_\lambda}       \\
        y_{t_{\lambda + 1}} \\
        \cdot               \\
        \cdot               \\
        y_{t_{k-1}}         \\
        y_{t_k}             \\
    \end{bmatrix}
    , \quad
    \matr{X} = \begin{bmatrix}
        y_{t_{\lambda - 1}}   & y_{t_{\lambda - 2}} & \cdots & y_{t_{1}} \\
        y_{t_\lambda}         & y_{t_{\lambda - 1}} & \cdots & y_{t_{2}} \\
        \cdot                 & \cdot               & \cdots & \cdot     \\
        \cdot                 & \cdot               & \cdots & \cdot     \\
        y_{t_{k - 2}}         & y_{t_{k - 3}}       & \cdots & y_{t_{k - \lambda}} \\
        y_{t_{k - 1}}         & y_{t_{k - 2}}       & \cdots & y_{t_{k - \lambda + 1}} \\
    \end{bmatrix}.
\end{equation*}
In this sandbox, the model has $k-\lambda + 1$ prediction to make, each being using a row vector in $\matr{X}$, denoted as $\matr{X}_i, \; i \in \{1, 2, \cdots, k-\lambda+1 \}$ and estimate the corresponding a row element in $\matr{y}$, denoted as $\matr{y}_i$. The idea is to find a model that best maps the rows in $\matr{X}$ to elements in $\matr{y}$ in general, and we say this is our best model $f$ that serves the objective of a $\tau$ ahead forecasting task given the time series we have.

\subsubsection{The Model}
We start by describing what a model is in more detail. Given the design matrix $\matr{X}$ and target $\matr{y}$ we made in the previous section, the forecasting objective is now transformed into coming up with a model $f$ that best maps the rows in $\matr{X}$ to the corresponding element in $\matr{y}$.

Consider $f$ as an arbitrary machine learning regression model with a known structure. Knowing the structure of $f$ implies we know the structure of its parameter set and how $f$ maps $\matr{X}_i$ to $\matr{y}_i$ for some $i$. Let $\theta$ be the mapping that generates the parameters that go into $f$. The output of $\theta$ is parameterised by its input set; let it be $\phi$. Parameter set like $\phi$ is called the \textit{hyperparameters} - it characterises the parameters of $f$. The model $f$ in our forecasting objective can thus be noted as
\begin{equation}\label{eq: estimate}
    f(\theta(\phi); \matr{X}) = \widehat{\matr{y}} \sim \matr{y}.
\end{equation}
To better measure the performance of such an estimation, we define a fitness function $\mathcal{E}$. The fitness function takes the estimations generated by $f$ and returns a real number signifying how well they fit the target. We can finally formulate our modelling objective as
\begin{equation}
    \arg_{\theta(\phi)} \max \mathcal{E}(f(\theta(\phi); \matr{X}), \matr{y}).
\end{equation}
This process is what we call \textit{training the model}.

To give an example, if $f$ is a simple linear regression model, then we know $\theta$ gives a tuple of real numbers (known as weights) which the model uses to generate a linear combination of its inputs; in this case, a row matrix $\matr{X}_i$. Specifications of $\theta$ are then controlled by its input $\phi$, e.g., whether there is an intercept term or the number of elements of the tuple. Note that the number of elements in the tuple depends on the number of lags $\lambda$ we adopted in making the design matrix $\matr{X}$, i.e., $\lambda \in \phi$. Not knowing the exact values of $\theta$ (and certainly $\phi$ as well) describes the state of the model $f$ being untrained. Then the modelling objective is to find $\phi$ and $\theta$ such that $\mathcal{E}(f(\theta(\phi); \matr{X}), \matr{y})$ is maximised.

\subsubsection{The Statistical Resemblance}
Analogously, training a machine learning model can be put into statistical terms. In particular, it resembles the Quasi-Maximum Likelihood Estimation (QMLE) process with some minor tweaks. Consider our objective with $Y$, but with the elements following an arbitrary distribution $\mathcal{D}$ characterised by $\theta$, i.e., $Y_{t_i} \sim \mathcal{D}(\theta), \; \forall \; t_i \in t$\footnote{The `Quasi-' simply means we do not know whether the distribution $\mathcal{D}$ is Gaussian or not (see White \citeyear{white1982maximum}).}. Let $g_{Y_{t_s} | \mathcal{Y}_{t_k}}(\cdot; \theta)$ be the conditional joint probability density function (pdf) of the random variable $Y_{t_s}$ given $\mathcal{Y}_{t_k}$ and $\theta$. Then the expression
\begin{equation*}
    g_{Y_{t_s} | \mathcal{Y}_{t_k}}(y_{t_s}| y_{t_k} ; \theta)
\end{equation*}
describes the probability of observing $Y_{t_s} = y_{t_s}$ given the past observations and parameter $\theta$. Then the objective of QMLE is to find the $\theta$ conditional on observing $\mathcal{Y}_{t_k}$, under which $y_{t_s}$ is most likely to be observed. We can formalise such objectives as
\begin{equation*}
    \arg_{\theta} \max g_{Y_{t_s} | \mathcal{Y}_{t_k}}(\theta ; y_{t_s} | y_{t_k}).
\end{equation*}
The objective function that is to be optimised is called the \textit{likelihood function}, denoted as $\mathcal{L}(\theta)$. $\mathcal{L}(\theta)$ is essentially still a pdf. It returns the probability of observing $y_{t_s}$ conditional on $y_{t_k}$ with the parameter $\theta$. Maximising such likelihood function with respect to $\theta$ is thus equivalent to finding a $\theta$ dictating the generating mechanism of the random variable $Y_{t_s}$ such that it is most likely to be observed as $y_{t_s}$.

Training a machine learning model bears some resemblance to QMLE. Training a model aims to find a mechanism to reproduce the target with the observations. At the same time, QMLE tries to find the set of parameters characterising the distribution of the target variable conditional on its past realisations. The outcome of training an ML model is to have a deterministic function that serves the purpose of forecasting. On the other hand, QMLE yields a set of parameters dictating the underlying distribution of the target variables, i.e., you do not end up having a recipe for making deterministic values but a probabilistic distribution. Both methodologies tackle the problem with an optimisation framework involving an objective function: QMLE utilises the probability density function (pdf) that comes with a random variable with a known distribution. ML modelling devises a fitness function to evaluate the goodness of the estimation. We hope this section contributes to a better theoretical understanding of ML modelling in terms of statistical analysis.

\section{Target Transformation in Univariate Time Series Forecasting}


\section{Directional Change Intrinsic Time Framework}
